{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GAN.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "VnvqxDEYzJvI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import *\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from keras.optimizers import *\n",
        "import math\n",
        "from PIL import Image\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UGjtwnVmzoYw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def generator_model():\n",
        "  model = Sequential()\n",
        "  model.add(Dense(input_dim=100,output_dim=1024))\n",
        "  model.add(Activation('tanh'))\n",
        "  model.add(Dense(128*7*7))\n",
        "  \n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Activation('tanh'))\n",
        "  \n",
        "  model.add(Reshape((7,7,128),input_shape=(128*7*7,)))\n",
        "  \n",
        "  model.add(UpSampling2D(size=(2,2)))\n",
        "  \n",
        "  model.add(Conv2D(64,(5,5),padding='same'))\n",
        "  model.add(Activation('tanh'))\n",
        "  model.add(UpSampling2D(size=(2,2)))\n",
        "  \n",
        "  model.add(Conv2D(1,(5,5),padding='same'))\n",
        "  model.add(Activation('tanh'))\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "iTt3AtXD2qDh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def discriminator_model():\n",
        "  model = Sequential()\n",
        "  model.add(Conv2D(64,(5,5),input_shape=(28,28,1)))\n",
        "  model.add(Activation('tanh'))\n",
        "  \n",
        "  model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "  model.add(Conv2D(128,(5,5)))\n",
        "  model.add(Activation('tanh'))\n",
        "  model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "  \n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(1024))\n",
        "  model.add(Activation('tanh'))\n",
        "  \n",
        "  model.add(Dense(1))\n",
        "  model.add(Activation('sigmoid'))\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XnPKicby3YWA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def generator_containing_discriminator(g,d):\n",
        "  model = Sequential()\n",
        "  model.add(g)\n",
        "  d.trainable = False\n",
        "  model.add(d)\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rza9-39V3tjB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "y_train = y_train.reshape(y_train.shape[0],1)\n",
        "y_test = y_test.reshape(y_test.shape[0],1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Ev9LW3g24Twf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "_train = (x_train,y_train)\n",
        "_test = (x_test,y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "z6snylAK7h1Z",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def combine_images(generated_images):\n",
        "    #生成图片拼接\n",
        "    num = generated_images.shape[0]\n",
        "    width = int(math.sqrt(num))\n",
        "    height = int(math.ceil(float(num)/width))\n",
        "    shape = generated_images.shape[1:3]\n",
        "    image = np.zeros((height*shape[0], width*shape[1]),\n",
        "                     dtype=generated_images.dtype)\n",
        "    for index, img in enumerate(generated_images):\n",
        "        i = int(index/width)\n",
        "        j = index % width\n",
        "        image[i*shape[0]:(i+1)*shape[0], j*shape[1]:(j+1)*shape[1]] = \\\n",
        "            img[:, :, 0]\n",
        "    return image"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pPl_BlDG4AKe",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def train(train, test, batch_size):\n",
        "  (x_train,y_train) = train\n",
        "  (x_test,y_test) = test\n",
        "  x_train = (x_train.astype(np.float32) - 127.5) / 127.5\n",
        "  \n",
        "  d = discriminator_model()\n",
        "  g = generator_model()\n",
        "  d_on_g = generator_containing_discriminator(g,d)\n",
        "  \n",
        "  d_optim = SGD(lr=0.001,momentum=0.9,nesterov=True)\n",
        "  g_optim = SGD(lr=0.001,momentum=0.9,nesterov=True)\n",
        "  \n",
        "  g.compile(loss='binary_crossentropy',optimizer='SGD')\n",
        "  d_on_g.compile(loss='binary_crossentropy',optimizer=g_optim)\n",
        "  \n",
        "  # 前一个架构训练了生成器，所以在训练判别器之前先要设定其为可训练。\n",
        "  d.trainable = True\n",
        "  d.compile(loss='binary_crossentropy',optimizer=d_optim)\n",
        "  \n",
        "  for epoch in range(30):\n",
        "    print(\"Epoch is\",epoch)\n",
        "    \n",
        "    for index in range(int(x_train.shape[0] / batch_size)):\n",
        "      noise = np.random.uniform(-1,1,size=(batch_size,100))\n",
        "      image_batch = x_train[index*batch_size:(index+1)*batch_size]\n",
        "      \n",
        "      image_batch = image_batch.reshape(image_batch.shape[0],28,28,1)\n",
        "      generated_image = g.predict(noise,verbose=0)\n",
        "      \n",
        "      #print('g shape:',generated_image.shape)\n",
        "      #print('i shape:',image_batch.shape)\n",
        "      \n",
        "      if index % 100 == 0:\n",
        "        image = combine_images(generated_image)\n",
        "        image = image*127.5 + 127.5\n",
        "        Image.fromarray(image.astype(np.uint8)).save('./GAN/'+str(epoch)+'_'+str(index)+'.png')\n",
        "      \n",
        "      x = np.concatenate((image_batch,generated_image))\n",
        "      y = [1]*batch_size + [0]*batch_size\n",
        "      \n",
        "      d_loss = d.train_on_batch(x,y)\n",
        "      print('batch:',index,', d_loss:',d_loss)\n",
        "      \n",
        "      noise = np.random.uniform(-1,1,(batch_size,100))\n",
        "      d.trainable = False\n",
        "      \n",
        "      g_loss = d_on_g.train_on_batch(noise,[1]*batch_size)\n",
        "      d.trainable = True\n",
        "      print('batch:',index,', g_loss:',g_loss)\n",
        "      \n",
        "      "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4ngYWPwg8oO8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train(_train,_test,batch_size=128)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-fxTXU7D-ywd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
